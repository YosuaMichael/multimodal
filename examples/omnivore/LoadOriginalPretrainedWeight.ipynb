{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ef9a30-174d-4ea3-b4a0-7c465e4c3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchmultimodal.models.omnivore as omnivore\n",
    "\n",
    "from PIL import Image\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e221ba-528e-4f09-9d49-d0f54a577bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def custom_load_state_dict(model, pretrained_state_dict):\n",
    "    # Convert the pretrained_state_dict so it have the same keys as the model\n",
    "    # then load the value of the weight into the model\n",
    "    pretrained_keys = list(pretrained_state_dict.keys())\n",
    "    model_keys = list(model.state_dict().keys())\n",
    "    key_mapping = {pretrained_keys[i]: model_keys[i] for i in range(len(model_keys))}\n",
    "    updated_pretrained_state_dict = collections.OrderedDict({key_mapping[key]: val for key, val in pretrained_state_dict.items()})\n",
    "    model.load_state_dict(updated_pretrained_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b998df-4c99-4f18-a408-a1feef5c483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/yosuamichael/.cache/torch/hub/facebookresearch_omnivore_main\n",
      "/Users/yosuamichael/.pyenv/versions/3.9.10/envs/multimodal-3.9/lib/python3.9/site-packages/torch/functional.py:476: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2353.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28945041\n"
     ]
    }
   ],
   "source": [
    "# Load model from torch_hub\n",
    "mhub = torch.hub.load(\"facebookresearch/omnivore:main\", model=\"omnivore_swinT\")\n",
    "mhub.eval()\n",
    "print(count_parameters(mhub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ea7454-f1c1-449f-a33b-004c54a4ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3de763-8be6-450d-958b-0a01d4dc8b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28945041\n"
     ]
    }
   ],
   "source": [
    "m = omnivore.omnivore_swin_t()\n",
    "\n",
    "# Check that it have same number of parameter\n",
    "print(count_parameters(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1168d33-0d11-46df-bef4-51f1973c2f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yosuamichael/.pyenv/versions/3.9.10/envs/multimodal-3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "custom_load_state_dict(m, mhub.state_dict())\n",
    "m = m.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d192ad-4902-49e1-baf6-77e7474a33bf",
   "metadata": {},
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6345f3-97b5-46cd-b068-aea129aedde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-13 11:50:44--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 64:ff9b::34d9:aee8, 52.216.140.118\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|64:ff9b::34d9:aee8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35363 (35K) [application/octet-stream]\n",
      "Saving to: ‘imagenet_class_index.json’\n",
      "\n",
      "imagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2022-05-13 11:50:44 (410 KB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'library.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Download the example image file\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Uncomment to downlo!wget -O library.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/13-11-02-olb-by-RalfR-03.jpg/800px-13-11-02-olb-by-RalfR-03.jpg\u001b[39;00m\n\u001b[1;32m     15\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m image_pil \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image_pil)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/multimodal-3.9/lib/python3.9/site-packages/PIL/Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3068\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3069\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'library.jpg'"
     ]
    }
   ],
   "source": [
    "# Download imagenet class and image\n",
    "# Uncomment to download\n",
    "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json -O imagenet_class_index.json\n",
    "with open(\"imagenet_class_index.json\", \"r\") as f:\n",
    "    imagenet_classnames = json.load(f)\n",
    "\n",
    "# Create an id to label name mapping\n",
    "imagenet_id_to_classname = {}\n",
    "for k, v in imagenet_classnames.items():\n",
    "    imagenet_id_to_classname[k] = v[1] \n",
    "\n",
    "# Download the example image file\n",
    "# Uncomment to download\n",
    "!wget -O library.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/13-11-02-olb-by-RalfR-03.jpg/800px-13-11-02-olb-by-RalfR-03.jpg\n",
    "\n",
    "image_path = \"library.jpg\"\n",
    "image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d91191-d461-4ae7-93cf-f8eb325133be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize(224),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "image = image_transform(image_pil)  # C H W\n",
    "\n",
    "# Adding batch and time (D) dimension\n",
    "image = image.unsqueeze(0).unsqueeze(2)  # B C D H W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4b65b-e9ce-48e3-9f1b-e79acb5a38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image, input_type=\"image\")\n",
    "        pred_classes = prediction.topk(k=5).indices\n",
    "\n",
    "    pred_class_names = [imagenet_id_to_classname[str(i.item())] for i in pred_classes[0]]\n",
    "    print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4305dd1-64ef-4a0f-b817-f5efe5f23980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test both model to infer the same image and make sure the output classes are the same\n",
    "infer(m)\n",
    "infer(mhub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c2578-1cba-478c-8909-f47330e1b376",
   "metadata": {},
   "source": [
    "# Make sure the output of the trunk / encoder are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85f5d7-f77d-47d3-8bec-3bfa51687953",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_feature = m.encoder(image)\n",
    "mhub_feature = mhub.trunk(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caf4aa-b964-4969-b531-318b9721bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first 10 features are the same\n",
    "m_feature.flatten()[:10], mhub_feature[0].flatten()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd36e03-c86a-4d4f-a83a-b8ff3bd757b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all the features are the same\n",
    "np.all(np.array(m_feature == mhub_feature[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
